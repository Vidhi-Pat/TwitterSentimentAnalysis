{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that s a bummer you shoulda got david car...       0\n",
       "1  is upset that he can t update his facebook by ...       0\n",
       "2  i dived many times for the ball managed to sav...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it s not behaving at all i m mad why am i h...       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv,index_col=0)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1596753 entries, 0 to 1596752\n",
      "Data columns (total 2 columns):\n",
      "text      1596753 non-null object\n",
      "target    1596753 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = my_df.text\n",
    "y = my_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1564817 entries with 50.00% negative, 50.00% positive\n",
      "Validation set has total 15968 entries with 50.26% negative, 49.74% positive\n",
      "Test set has total 15968 entries with 50.18% negative, 49.82% positive\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
    "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
    "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
    "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = model.docvecs[prefix]\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_vectors(model1,model2, corpus, size):\n",
    "    vecs = np.zeros((len(corpus), size))\n",
    "    n = 0\n",
    "    for i in corpus.index:\n",
    "        prefix = 'all_' + str(i)\n",
    "        vecs[n] = np.append(model1.docvecs[prefix],model2.docvecs[prefix])\n",
    "        n += 1\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [t.split() for t in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phrases = Phrases(tokenized_train)\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'mayor', 'of', 'new_york', 'was', 'there']\n"
     ]
    }
   ],
   "source": [
    "sent = [u'the', u'mayor', u'of', u'new', u'york', u'was', u'there']\n",
    "print(bigram[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omg report cards tomorrow'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[627092]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['omg', 'report_cards', 'tomorrow']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[x_train[627092].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_tweets_bg(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(LabeledSentence(bigram[t.split()], [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "all_x = pd.concat([x_train,x_validation,x_test])\n",
    "all_x_w2v_bg = labelize_tweets_bg(all_x, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:580: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4246738.19it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dbow = Doc2Vec(dm=0, size=100, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dbow.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4246280.45it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4212851.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4136687.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4303586.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4292140.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4410347.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4338805.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4315007.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4373854.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4323342.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4325357.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4312907.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4372283.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4327090.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4361100.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4314454.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4326914.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4361935.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4374265.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4350516.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4386332.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4235171.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4337248.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4303473.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4291777.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4338783.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4291915.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4398431.61it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4315288.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 1596753/1596753 [00:00<00:00, 4324268.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_bg_dbow.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dbow.alpha -= 0.002\n",
    "    model_bg_dbow.min_alpha = model_bg_dbow.alpha\n",
    "\n",
    "train_vecs_dbow_bg = get_vectors(model_bg_dbow, x_train, 100)\n",
    "validation_vecs_dbow_bg = get_vectors(model_bg_dbow, x_validation, 100)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dbow_bg, y_train)\n",
    "\n",
    "clf.score(validation_vecs_dbow_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dbow.save('d2v_model_bg_dbow.doc2vec')\n",
    "model_bg_dbow = Doc2Vec.load('d2v_model_bg_dbow.doc2vec')\n",
    "model_bg_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model_bg_dmc = Doc2Vec(dm=1, dm_concat=1, size=100, window=2, negative=5, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
    "model_bg_dmc.build_vocab([x for x in tqdm(all_x_w2v_bg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_bg_dmc.train(utils.shuffle([x for x in tqdm(all_x_w2v_bg)]), total_examples=len(all_x_w2v_bg), epochs=1)\n",
    "    model_bg_dmc.alpha -= 0.002\n",
    "    model_bg_dmc.min_alpha = model_bg_dmc.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmc.most_similar('new_york')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs_dmc_bg = get_vectors(model_bg_dmc, x_train, 100)\n",
    "validation_vecs_dmc_bg = get_vectors(model_bg_dmc, x_validation, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_vecs_dmc_bg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(validation_vecs_dmc_bg, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bg_dmc.save('d2v_model_bg_dmc.doc2vec')\n",
    "model_bg_dmc = Doc2Vec.load('d2v_model_bg_dmc.doc2vec')\n",
    "model_bg_dmc.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
